[
  {
    "Pattern Name": "Retriever-Aware Training (RAT)",
    "Problem": "Large Language Models (LLMs) struggle to effectively use external tools via API calls, especially when the available APIs are massive, frequently updated, and the LLM is unaware of their existence or usage. Naive retrieval augmentation can sometimes hurt performance if the retrieved documents are irrelevant or inaccurate.",
    "Context": "An LLM needs to interact with a dynamic and extensive set of external APIs, whose documentation changes over time. The LLM must not only leverage this documentation but also learn to critically evaluate its relevance and accuracy during inference.",
    "Solution": "The LLM is finetuned on an instruction-tuned dataset where the user prompt is augmented with retrieved documentation. Crucially, the training process includes potentially incorrect retrieved documentation alongside the accurate ground truth in the LLM's response. This teaches the LLM to 'judge the retriever' at inference time, enabling it to use relevant documentation and ignore irrelevant context, relying on its baked-in domain-specific knowledge when retrieval fails. During inference, a retriever (e.g., BM25, GPTIndex) fetches the most up-to-date API documentation, which is then concatenated to the user prompt.",
    "Result": "The LLM demonstrates a strong capability to adapt to test-time document changes (e.g., API version updates, argument changes), improves performance compared to in-context learning, and substantially mitigates API argument hallucination errors. It maintains efficacy and accuracy over time despite documentation evolution.",
    "Related Patterns": "Retrieval-Augmented Generation (RAG), Instruction Finetuning, Tool-Augmented LLMs.",
    "Category": "LLM-specific",
    "Uses": "Enhancing LLMs for dynamic tool use, improving reliability of API generation, reducing hallucination in tool invocation, adapting to frequently updated documentation.",
    "Thinking": "This pattern is explicitly named 'Retriever-Aware Training (RAT)' in the text and described as a novel technique. It addresses a specific LLM problem (tool use, dynamic knowledge, hallucination) with a unique training methodology that involves both retrieval and finetuning, teaching the model to evaluate retrieved context."
  },
  {
    "Pattern Name": "Self-Instruct Finetuning for API Generation",
    "Problem": "Off-the-shelf LLMs struggle to accurately generate API calls for a vast, overlapping, and frequently updated set of millions of available APIs, often leading to incorrect or hallucinated API calls. Manually creating a comprehensive training dataset for such a scale is impractical.",
    "Context": "An LLM needs to be trained to translate natural language instructions into precise, actionable API calls, including relevant packages and step-by-step explanations. The target API ecosystem is large and constantly evolving.",
    "Solution": "Employ the self-instruct paradigm to generate synthetic instruction data. This involves providing a few in-context examples along with reference API documentation to a powerful LLM (e.g., GPT-4) and tasking it to generate real-world use cases that call upon the API. The generated instruction-API pairs are then used to finetune a base LLM (e.g., LLaMA) in a user-agent chat-style conversation format.",
    "Result": "The finetuned LLM (Gorilla) significantly outperforms both open-source and closed-source models in terms of API functionality accuracy and reduction in API argument hallucination errors, even in a zero-shot setting. It enables the LLM to accurately select from a large and changing set of tools.",
    "Related Patterns": "Instruction Finetuning, Self-Supervised Learning, Data Augmentation.",
    "Category": "Generative AI",
    "Uses": "Training LLMs for code generation (specifically API calls), scaling dataset creation for specialized LLM tasks, improving LLM's ability to follow complex instructions for tool use.",
    "Thinking": "The text explicitly mentions 'self-instruct finetuning' as a core component of Gorilla's training methodology. It addresses the problem of generating API calls from natural language, which is a generative AI task, and the self-instruct part is a specific AI training methodology for data creation and model adaptation."
  },
  {
    "Pattern Name": "Constraint-Aware API Selection",
    "Problem": "LLMs need to select APIs that not only fulfill a functional description but also adhere to specific user-defined constraints (e.g., performance, resource usage, accuracy, cost, latency). This requires the LLM to reason about and categorize API calls based on multiple constraint parameters.",
    "Context": "Users provide natural language prompts for API calls that include explicit or implicit constraints (e.g., 'image classification model that uses less than 10M parameters but maintains an ImageNet accuracy of at least 70%'). The LLM must navigate a landscape of available APIs, each with varying characteristics, to find the optimal match.",
    "Solution": "Incorporate instructions with embedded constraints into the LLM's training dataset. The API documentation used during training (and potentially retrieval during inference) includes detailed information about parameters, performance, efficiency, and other relevant metrics for each API. This allows the LLM to learn to comprehend and reason about these constraints when making API selections.",
    "Result": "The LLM demonstrates the ability to navigate APIs while considering trade-offs between constraints, even in challenging scenarios where accuracy drops across all models. It can select appropriate APIs that satisfy both functional and non-functional requirements.",
    "Related Patterns": "Knowledge & Reasoning, Multi-objective Optimization (implicit), Personalization.",
    "Category": "Knowledge & Reasoning",
    "Uses": "Enabling LLMs to make informed API choices based on user preferences, optimizing tool usage based on operational requirements, enhancing the practical applicability of LLM-generated code.",
    "Thinking": "The text dedicates a specific section to 'API Call with Constraints' and evaluates Gorilla's ability to handle them. This highlights a distinct AI capability for reasoning about multiple factors beyond simple functional matching, making it a knowledge and reasoning pattern."
  },
  {
    "Pattern Name": "AST-based Hallucination Detection for Code Generation",
    "Problem": "Evaluating the functional correctness and identifying hallucinations in LLM-generated API calls is challenging. Traditional NLP metrics are insufficient for code structure, and unit tests are often impractical due to multiple correct answers, overlapping functionality, and complex execution environments. Hallucinations can manifest as invoking entirely imagined tools or incorrect API usage.",
    "Context": "An LLM generates API calls in response to natural language prompts. A robust, automated, and offline method is needed to verify the correctness of these generated calls and distinguish between functional errors and outright hallucinations.",
    "Solution": "Define a hallucination as an API call that is not a subtree of any API in a predefined database. Use Abstract Syntax Tree (AST) subtree matching to compare the generated API call's AST with the ASTs of known, correct APIs in the dataset. This involves matching on API names and specified arguments, while accounting for optional arguments.",
    "Result": "The AST-based metric provides a precise measure of both functional correctness and API hallucination, showing a strong correlation with human evaluation. It enables efficient and robust offline evaluation of LLM-generated API calls, making it tractable to assess performance at scale.",
    "Related Patterns": "Code Analysis, Automated Testing (for AI-generated code), Semantic Parsing Evaluation.",
    "Category": "MLOps",
    "Uses": "Automated evaluation of LLM-generated code, benchmarking LLMs for tool use, improving the reliability and trustworthiness of AI-generated programs, identifying and quantifying hallucination in code generation.",
    "Thinking": "This is presented as a novel evaluation metric specifically for LLM-generated API calls, addressing the unique challenges of code correctness and hallucination in this context. It's a method for evaluating an AI system's output in a specialized domain, making it an MLOps pattern specific to ML workflow evaluation."
  },
  {
    "Pattern Name": "LLM-API Integration System",
    "Problem": "Large Language Models (LLMs) are limited by their static training data and unawareness of external, frequently updated tools/APIs, hindering their ability to perform complex computational tasks and act as flexible interfaces to the digital world.",
    "Context": "An LLM needs to extend its capabilities beyond traditional natural language processing by interacting with a dynamic, massive, and diverse ecosystem of external APIs to accomplish complex tasks and provide actionable code.",
    "Solution": "Design and implement a comprehensive system that tightly integrates an LLM with a vast API database. This system involves: 1) **API Database Curation:** Aggregating, filtering, and structuring API documentation into a standardized format (e.g., JSON objects with detailed fields like domain, functionality, arguments, performance). 2) **Synthetic Instruction Generation:** Employing a self-instruct paradigm with a powerful LLM to generate a large dataset of natural language instruction-API call pairs, including examples with user-defined constraints. 3) **Retriever-Aware Finetuning:** Finetuning a base LLM (e.g., LLaMA) using this dataset, where retrieved API documentation is incorporated during training to teach the LLM to adapt to test-time changes and critically evaluate the relevance of retrieved context. 4) **Inference with Dynamic Retrieval:** During inference, using a retriever to fetch the most up-to-date API documentation based on user queries, augmenting the prompt with this documentation, and having the finetuned LLM generate the precise API call and supporting explanation. 5) **AST-based Evaluation:** Utilizing Abstract Syntax Tree (AST) subtree matching for robust, offline evaluation of functional correctness and hallucination in the generated API calls.",
    "Result": "The integrated system (Gorilla) achieves state-of-the-art performance in generating accurate API calls across thousands of functions and libraries. It demonstrates strong adaptability to API changes, effectively reasons about user-defined constraints, and substantially mitigates API argument hallucination, transforming the LLM into a reliable tool-user.",
    "Related Patterns": "Tool-Augmented LLMs, Retrieval-Augmented Generation (RAG), Agentic AI, Knowledge Graph Integration, Instruction Finetuning.",
    "Category": "Tools Integration",
    "Uses": "Enabling LLMs to interact with external software and services, automating complex workflows requiring external tool use, building LLM-powered agents for digital interaction, enhancing LLM reliability and applicability in dynamic environments.",
    "Thinking": "This pattern describes the overarching system architecture and methodology (Gorilla) that combines several individual AI techniques (self-instruct, RAT, constraint reasoning, AST evaluation) to solve the fundamental problem of enabling LLMs to effectively use massive, dynamic API sets. The paper's first contribution explicitly states 'We introduce Gorilla the first system to enable largescale API integration with LLMs', indicating a system-level design pattern."
  },
  {
    "Pattern Name": "Structured API Documentation for LLM Consumption",
    "Problem": "Large Language Models (LLMs) struggle to effectively understand and utilize diverse, unstructured, and frequently updated API documentation from various sources, hindering their ability to generate accurate and constrained API calls.",
    "Context": "An LLM-powered system needs to interact with a vast and dynamic ecosystem of external APIs. The raw documentation for these APIs is often inconsistent, incomplete, or difficult for an LLM to parse and reason about directly.",
    "Solution": "Curate and standardize API documentation by converting disparate model cards and documentation into a uniform, machine-readable JSON object format. This format includes specific, semantically rich fields such as `domain`, `framework`, `functionality`, `apiname`, `apicall`, `apiarguments`, `environmentrequirements`, `examplecode`, `performance`, and `description`. This structured representation serves as a canonical knowledge base for the LLM and its associated retrieval system.",
    "Result": "Provides a consistent and easily parsable knowledge source for the LLM, enabling it to better comprehend API capabilities, parameters, and constraints. This leads to improved accuracy in API call generation, facilitates constraint-aware reasoning, and supports dynamic adaptation to API changes through efficient retrieval.",
    "Related Patterns": "Knowledge Representation, Information Extraction, Semantic Parsing (for internal LLM processing), Data Normalization (for external data).",
    "Category": "Knowledge & Reasoning",
    "Uses": "Building robust LLM-tool integration systems, enhancing LLM's ability to reason about external services, creating scalable knowledge bases for AI agents, improving the reliability of AI-generated code.",
    "Thinking": "This pattern describes a specific method of organizing external knowledge (API documentation) in a structured way that is optimized for consumption and reasoning by an AI model (LLM). The choice of fields and the conversion process are critical design decisions for the AI system's ability to perform its task of API generation and selection."
  }
]