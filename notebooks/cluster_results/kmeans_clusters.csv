Pattern Name,cluster
Prompt Chain,1
LeasttoMost Prompting,1
PlanandSolve Prompting,1
Planning,1
Plan-and-Solve Paradigm,1
Two-LLM Framework for Reasoning Step Selection and Generation,1
Structured Output / Plan Generation,1
Iterative Self-Correction with Automated Feedback,2
Hybrid Utility Function Design,2
Contextual Prompt Engineering,2
SelfRefine,2
Progressive Response Disclosure,2
Predictive Reranking (Trained LM-Dedicated Reranker),3
Unified Ranking and Generation Instruction Tuning (RankRAG),3
Retrieve-Rerank-Generate Inference Pipeline,3
Zero-Shot LM Reranking,3
Multi-Source Data Blending for Unified Instruction Tuning,3
Unified Instruction Format for Multi-task LLM Training,3
Data-Efficient Ranking Integration,3
Index Hotswapping (for Knowledge Updates),4
Human-Readable/Writable Nonparametric Memory,4
Parametric and Non-Parametric Memory Combination,4
RecursionofThought,6
TreeofThought (ToT),6
Tree of Thoughts (ToT) / Graph of Thoughts (GoT),6
Tree-of-Thoughts (ToT),6
Graph-of-Thoughts (GoT),6
Meta Prompting,7
Emergent Tool Composition,7
Automated Dataset Generation for Tool-Augmented LLMs,7
LLM as Tool Maker/Creator,7
AI Tool Creation,7
Cross-Lingual Self Consistent Prompting (CLSP),8
Universal Self-Adaptive Prompting (USP),8
Consistency-based Self-adaptive Prompting (COSP),8
Active Prompting,8
Knowledge-Driven Chain-of-Thought (KDCoT) / Retrieval-Enhanced Reasoning (RR),10
Vector Database for Knowledge Retrieval,10
Retrieval Augmented Generation (RAG),10
Knowledge Augmentation,10
Retrieval Augmentation,10
Retrieval-Augmented Generation (RAG),10
Iterative Retrieval Augmentation,10
Retrieval Augmented Generation (RAG),10
Single-step Retrieval-Augmented Generation (Single-step RAG),10
Modular Knowledge Consolidation Pipeline,10
Retrieval Augmented Generation (RAG) - Inference,11
Retrieval-Augmented Generation (RAG),11
Nearest Neighbor Language Models (kNN-LM),11
Retrieval Augmented Generation (RAG),11
Retrieval-Augmented Generation (RAG) for Knowledge Graphs,11
ThinkonGraph (ToG) Algorithmic Framework,12
"KG-Agent Framework (KGAgent, ThinkonGraph)",12
LLMs as Explainer,14
Constitutional AI for Ethical Alignment,14
PairedImage Prompting,15
ImageasText Prompting,15
Binary Score (for Evaluation),16
Linear Scale (for Evaluation),16
Partial Dependence Plots (PDPs),17
Individual Conditional Expectation (ICE) Plots,17
Chain-of-Thought (CoT) Prompting,18
Chain-of-Thought (CoT) Prompting,18
Chain-of-Thought Reasoning,18
Chain-of-Thought Finetuning,18
ChainofThought (CoT) Prompting,18
Cumulative Reasoning,18
ThreadofThought (ThoT) Prompting,18
Step-by-Step Reasoning (Chain-of-Thought / CoT),18
Chain of Thought (CoT) Prompting,18
Chain-of-Thought (CoT) Prompting,18
Template-Based Prompting for Controlled Generation,19
State Representation for Agentic LLM,19
Structured Action Space for Agentic LLM,19
Plug-and-Play LLM Augmentation Framework,20
Plug-and-Play LLM Module,20
Plug-and-Play LLM-KG Integration,20
Program-Aided Language Models (PAL) Prompting,21
ProgramofThoughts,21
Program-aided Language Model (PAL),21
Tool-Integrated Reasoning Loop,21
Context Window Management,22
Long Context Management for LLMs,22
Memory Management (Working Memory / Short-Term Memory / Long-Term Memory),22
Imitation Learning for Tool-Use Trajectories,23
Interactive Tool Use Trajectory Curation,23
Output Space Shaping,23
Learning from Demonstrations (Behavioral Cloning),23
Teacher-Assisted Trajectory Correction,23
Behavior Cloning for Initial Skill Acquisition,23
Learning from Feedback (Reinforcement Learning for Tool Use),23
In-Context Learning for Tool Use,23
Curriculum Tool Learning,23
Few-Shot Prompting for Structured Trajectory Generation,23
Automatic ChainofThought (AutoCoT) Prompting,24
ZeroShot CoT,24
Automatic Directed CoT (AutoDiCoT),24
Analogical Prompting,24
Faithful ChainofThought,24
Tabular ChainofThought (TabCoT),24
Automatic Prompt Engineer (APE),24
MetaReasoning over Multiple CoTs,24
MemoryofThought Prompting,24
Iterative Retrieval-Augmented Generation (Iterative RAG),25
Adaptive Retrieval (Entity Frequency-based),25
Confidence-Based Iterative Retrieval,25
Adaptive Retrieval-Augmented Generation (AdaptiveRAG),25
Iterative Retrieval and Decision-Making,25
Task Automation via Tools,26
Tool Use / Tool Augmentation,26
Agentic Architecture,26
Tool Orchestration / Chaining,26
Live Web Access with Controlled Interaction,26
Parameter Extraction and Tool Invocation,26
Tool Retrieval and Selection,26
Exemplar Ordering,27
Vanilla Prompting (for bias mitigation),27
Bias-Aware Design & Mitigation,27
Selecting Balanced Demonstrations (for bias mitigation),27
LLMEVAL Framework,28
ChatEval Framework,28
Likert Scale (for Evaluation),28
Pairwise Evaluation,28
Model-Generated Guidelines (for evaluation),28
Separate LLM Extractor,28
Role-based Evaluation,28
Adversarial Evaluation for Truthfulness,28
GEVAL Framework,28
LLM-based Evaluation (Autorater/LLMEval),28
AST-based Hallucination Detection for Code Generation,28
ReAct (Reasoning and Acting),29
ReACT (Reasoning and Acting),29
ReAct (Reasoning and Acting),29
Reasoning and Acting (ReAct),29
Inter-Tool Dependency Management,30
Personalized Tool Learning,30
Code Generation with Tool Integration,30
Intent Understanding,30
Tool Understanding (via Prompting),30
Tool-Augmented Foundation Model,30
Knowledge Conflict Resolution (in Tool Augmentation),30
Transparent Tool-Use Reasoning,30
Multi-Agent Collaboration for Tool Learning,30
Scientific Discovery with Tool Manipulation,30
World Model / Simulation-based Planning,31
Backtracking / Heuristic Search,31
Long-Horizon Planning,31
DivExplorer (Divergent Subgroup Exploration),32
DivExplorer Interactive System (Interactive Divergent Subgroup Exploration),32
Retrieval Query Length Optimization,33
Conditional Retrieval,33
Retrieval Stride Optimization,33
Optimal Document Count for In-Context Learning,33
ChainofDictionary (CoD),34
Dictionary-based Prompting for Machine Translation (DiPMT),34
SelfCalibration,35
Verbalized Score (for confidence calibration),35
Metacognitive Prompting,35
Confidence Estimation (Self-rated Probabilities),35
Cognitive Load Management,36
Task Decomposition,36
Task Decomposition and Planning,36
Task Decomposition,36
FewShot Prompting,38
ZeroShot Prompting,38
Self-Generated InContext Learning (SGICL),38
Hybrid Pruning Strategy (LLM + Lightweight Model),39
Batch Prompting for Pruning,39
Batch Prompting (for Evaluation),39
LLM-API Integration System,40
Instruction Finetuning (IFT),40
Self-Instruct Finetuning for API Generation,40
Retriever-Aware Training (RAT),40
Constraint-Aware API Selection,40
LLM-based Tool Learning,41
Robust Tool-Augmented Processing,41
External Knowledge Augmentation,41
Tool Augmentation,41
Browser-Assisted LLM,41
Multimodal Interaction Augmentation,41
Structured API Documentation for LLM Consumption,41
Tool-Augmented Response Synthesis,41
"Modular Reasoning, Knowledge and Language (MRKL) System",41
Domain-Specific Tool Integration,41
Memory Augmentation for LLMs,41
RAGToken,42
RAGSequence,42
Marginalization over Latent Documents,42
Auxiliary Training Signal (Statement Reconstruction),43
Domain-Specific Finetuning (DSF),43
Fixed Document Index (during Fine-tuning),43
End-to-End Retriever Training (for RAG Domain Adaptation),43
Asynchronous Knowledge Base Updates,43
End-to-End Joint Training (Retriever-Generator),43
Multilevel Dynamic Knowledge Caching for RAG (RAGCache),44
PagedAttention,44
KV Cache Reuse,44
Swap-Out-Only-Once Cache Strategy,44
Dynamic Speculative Pipelining for RAG,44
Knowledge Tree for RAG KV Cache,44
Prefix-aware GreedyDualSizeFrequency (PGDSF) Cache Replacement,44
Cache-aware Request Reordering for RAG,44
SkeletonofThought,46
Parallel Tool Execution,46
Iterative Prompting for Guided KG Exploration and Reasoning,47
Relation-Based Reasoning (ToGR),47
LLM-Guided Beam Search for KG Exploration,47
Self-Evaluation and Termination Condition (for iterative reasoning),47
xPlain (Interactive Human-in-the-Loop Explanation Framework),48
LACE (Local Agnostic attribute Contribution Explanation),48
Counterfactual Explanations,48
Universal SelfConsistency,50
DiVeRSe,50
SelfConsistency,50
Planning with Extrospective Reasoning,53
Planning with Introspective Reasoning,53
Emotion Prompting,55
Role Prompting,55
Query Complexity Classifier,56
Automatic Classifier Training Data Generation (for Query Complexity),56
Mixture of Reasoning Experts (MoRE),57
Contrastive CoT Prompting,57
Complexity-based Prompting,57
Uncertainty-Routed CoT Prompting,57
Voyager,59
Ghost in the Minecraft (GITM),59
InCLT Crosslingual Transfer Prompting,60
PARC Prompts Augmented by Retrieval Cross-lingually,60
Cultural Awareness (for cultural adaptation),60
XLT Cross-Lingual Thought Prompting,60
Prompt Mining,60
Self-Correcting with Tool-Interactive Critiquing (CRITIC),61
Perceiver (Feedback Processing),61
Multi-Round Self-Correction,61
Feedback Loop / Self-Correction,61
Iterative Task Solving (with Feedback),61
Self-Correction / Feedback Loop,61
Self-Reflection for RAG (SelfRAG),61
Faithful Reasoning with Verifier (Entailer),62
Monte-Carlo Planning for Faithful Reasoning (FAME),62
Agentic Policy for LLM Orchestration,63
Staged Policy Learning for Agentic LLMs,63
Agentic Working Memory,63
Verbalizer,64
Styling (for Evaluation),64
Thorough Decoding (RAGSequence),65
Fast Decoding (RAGSequence),65
Dense Passage Retrieval (DPR),66
FAISS Indexing for Efficient Retrieval,66
Dense Passage Retrieval (DPR),66
Output Formatting,67
Style Prompting,67
Prompt-based Defenses,67
Debate-Style Evidence Aggregation,68
Trust Calibration through Transparency,68
Reference-Supported Generation,68
Gradient-free Instructional Prompt Search (GrIPS),69
Max Mutual Information Method,69
Prompt Optimization with Textual Gradients (ProTeGi),69
SelfAsk,70
Question Clarification,70
Rephrase and Respond (RaR),71
Rereading (RE2),71
Dual Data Collection for Agentic LLM Training,72
Human-in-the-Loop Data Collection Interface,72
Rejection Sampling (Best-of-N),72
KL Regularization in RLHF,72
Human Feedback for Quality Optimization (Reward Modeling & RLHF),72
Retrieval Augmented Fine-Tuning (RAFT),74
Irrelevant Context Robustness Training,74
Distractor-Aware Finetuning,74
Reasoning on Graphs (RoG) / Planning-Retrieval-Reasoning Framework,75
Semantic Parsing for Knowledge Graph Question Answering (KGQA),75
LLM-KG Tight-Coupling Paradigm,75
LLM Fallback to Inherent Knowledge,75
Knowledge Traceability and Correctability via Explicit Reasoning Paths,75
LLM-based Topic Entity Extraction,75
Formalism-Enhanced Reasoning,75
Unified Retrieval and Reasoning,75
Instruction Tuning for LLM-KG Integration,75
VoteK Exemplar Selection,76
KNN Exemplar Selection,76
Negative Prompting,77
Prompt Modifiers,77
Prompt-Tuning a Frozen LM as a Reader,78
Open-Book Question Answering with InContext RALM,78
InContext Retrieval-Augmented Language Modeling (InContext RALM),78
Sufficient Context Autorater,79
Finetuning for Controlled Abstention,79
Selective Generation with Sufficient Context Signal,79
Duty Distinct ChainofThought (DDCoT),80
Multimodal GraphofThought,80
ChainofImages (CoI),80
Generalizable Tool Learning (Interface Unification),83
Meta Tool Learning,83
Two-Stage QA Pipeline (Retriever-Reader Architecture),87
Retrieval Augmented Generation (RAG),87
Retrieval-Augmented Generation (RAG),87
Pretrained Component Integration (Retriever & Generator),87
Synthetic QA Data Generation,87
Commonsense Reasoning,88
Constraint Satisfaction,88
LLMs as Content Interpreter,89
LLMs as Knowledge Base,89
LLMs for Automated ML Selection,89
Efficient LLM Fine-tuning,89
LLMs as Personalized Content Creator,89
LLMs for Direct Recommendation (In-context Learning & CoT),89
LLMs as Conversational Agent,89
Multi-step Retrieval-Augmented Generation (Multi-step RAG),90
Query Decomposition for Multi-hop QA,90
DemonstrateSearchPredict (DSP),90
Interleaved Retrieval guided by ChainofThought (IRCoT),90
Reflexion,91
Reflexion,91
Tool-Integrated Reasoning Agent (ToRA),92
Tool-Integrated Reasoning Agent (TORA),92
Multi-Aspect Prompting and Selection (MAPS),96
InteractiveChainPrompting (ICP),96
Iterative Prompting (for MT),96
Decomposed Prompting for MT (DecoMT),97
Decomposed Prompting (DECOMP),97
Decomposed Prompting (DecomP),97
3D Prompting,99
Segmentation Prompting,99
Reversing ChainofThought (RCoT),100
VerifyandEdit,100
SelfVerification,100
